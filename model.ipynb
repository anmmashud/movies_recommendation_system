{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13619598,"sourceType":"datasetVersion","datasetId":8655521},{"sourceId":13621685,"sourceType":"datasetVersion","datasetId":8657082}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\">Movies Recommendation System</h1>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-black?style=for-the-badge&logo=github)](https://github.com/anmmashud/movies_recommendation_system)\n\n[![Web Scraper](https://img.shields.io/badge/Web%20Scraper-Kaggle-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/code/anmmashud/tmdb-web-scrapping-using-api)\n\n[![Live Preview](https://img.shields.io/badge/Live%20Preview-Streamlit-brightgreen?style=for-the-badge&logo=streamlit)](https://movies-recommendation-system-by-anmmashud.streamlit.app)\n\n[![Documentation](https://img.shields.io/badge/Documentation-anmmashud-orange?style=for-the-badge&logo=ghost)](https://anmmashud.xyz/blog/2025/rs_tmdb_5000_movies/)\n","metadata":{}},{"cell_type":"markdown","source":"**To-Do**\n- add production companies\n- add taglines\n- more language\n- apply algoriths for feature engeneering","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport copy\nimport ast\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T15:24:20.795810Z","iopub.execute_input":"2025-11-05T15:24:20.796161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/all-english-movies-1980-to-2025-from-tmdb/tmdb_all_movies_(1980-2025)_v1.csv')\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:03:18.088585Z","iopub.execute_input":"2025-11-05T07:03:18.089173Z","iopub.status.idle":"2025-11-05T07:03:24.084586Z","shell.execute_reply.started":"2025-11-05T07:03:18.089146Z","shell.execute_reply":"2025-11-05T07:03:24.083709Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(439230, 11)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"df2 = df.copy()\ndf2.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:08:10.602988Z","iopub.execute_input":"2025-11-05T07:08:10.603815Z","iopub.status.idle":"2025-11-05T07:08:10.651953Z","shell.execute_reply.started":"2025-11-05T07:08:10.603782Z","shell.execute_reply":"2025-11-05T07:08:10.651148Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:08:13.922380Z","iopub.execute_input":"2025-11-05T07:08:13.923070Z","iopub.status.idle":"2025-11-05T07:08:14.610271Z","shell.execute_reply.started":"2025-11-05T07:08:13.923043Z","shell.execute_reply":"2025-11-05T07:08:14.609491Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"id                   439226\ntitle                382581\noverview             420499\nrelease_date          16568\noriginal_language         1\ngenre_ids              8929\nadult                     2\npopularity            45873\ntop_cast             305370\ndirectors            170565\nkeywords              90664\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# making another copy where we will do data preproccessing\ndf3 = df2.copy()\ndf3['movie_id'] = df3['id']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:18:42.832554Z","iopub.execute_input":"2025-11-05T07:18:42.832870Z","iopub.status.idle":"2025-11-05T07:18:42.873367Z","shell.execute_reply.started":"2025-11-05T07:18:42.832847Z","shell.execute_reply":"2025-11-05T07:18:42.872656Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# droping unneccessery columns. you can alsso do this by creating new dataframe\ndf3 = df3.drop(columns=['id', 'original_language','popularity'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:18:51.775266Z","iopub.execute_input":"2025-11-05T07:18:51.775603Z","iopub.status.idle":"2025-11-05T07:18:51.843177Z","shell.execute_reply.started":"2025-11-05T07:18:51.775580Z","shell.execute_reply":"2025-11-05T07:18:51.842418Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# removing rows with null title\ndf3 = df3.dropna(subset=['title'])\n# replacing overview with ` `. because we will concat overview with title so we will get a synthethic overview\ndf3 = df3.fillna({'overview':' '})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:20:37.613903Z","iopub.execute_input":"2025-11-05T07:20:37.614218Z","iopub.status.idle":"2025-11-05T07:20:37.815017Z","shell.execute_reply.started":"2025-11-05T07:20:37.614194Z","shell.execute_reply":"2025-11-05T07:20:37.814028Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"title               0\noverview        11104\nrelease_date        0\ngenre_ids           0\nadult               0\ntop_cast            0\ndirectors           0\nkeywords            0\nmovie_id            0\ndtype: int64"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# see the difference\nprint(df2.shape)\nprint(df3.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:25:51.804870Z","iopub.execute_input":"2025-11-05T07:25:51.805323Z","iopub.status.idle":"2025-11-05T07:25:51.810460Z","shell.execute_reply.started":"2025-11-05T07:25:51.805295Z","shell.execute_reply":"2025-11-05T07:25:51.809425Z"}},"outputs":[{"name":"stdout","text":"(439230, 11)\n(439227, 9)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"print(\"==== DUPLICATE ====\\n\",df3.duplicated().sum())\nprint(\"==== UNIQUE ====\\n\",df3.nunique())\nprint(\"==== NULL ====\\n\",df3.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:30:40.657094Z","iopub.execute_input":"2025-11-05T07:30:40.657525Z","iopub.status.idle":"2025-11-05T07:30:42.873828Z","shell.execute_reply.started":"2025-11-05T07:30:40.657495Z","shell.execute_reply":"2025-11-05T07:30:42.872777Z"}},"outputs":[{"name":"stdout","text":"==== DUPLICATE ====\n 0\n==== UNIQUE ====\n title           382581\noverview        420497\nrelease_date     16568\ngenre_ids         8929\nadult                2\ntop_cast        305368\ndirectors       170564\nkeywords         90664\nmovie_id        439223\ndtype: int64\n==== NULL ====\n title           0\noverview        0\nrelease_date    0\ngenre_ids       0\nadult           0\ntop_cast        0\ndirectors       0\nkeywords        0\nmovie_id        0\ndtype: int64\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"### Genre Code Function\n\naccording to our scraped data, we have ids for genre. we dont need to convert them acctual name. even we have also some columns like `keywords` has empty list `[]`. we will kepp them as it is. because our model will will only recognize the common tags. so if we convert it into a general form like `prefix`+`id` then it will be an unique tags for each movie. but if you want you can also convert it into original genre name. but it will need tmdb api and cost extra api calls\n\n**To-Do**\n- apply feature engeneering: Scaling","metadata":{}},{"cell_type":"code","source":"df4 = df3.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:41:33.139635Z","iopub.execute_input":"2025-11-05T08:41:33.139978Z","iopub.status.idle":"2025-11-05T08:41:33.535409Z","shell.execute_reply.started":"2025-11-05T08:41:33.139954Z","shell.execute_reply":"2025-11-05T08:41:33.534421Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Making a function to modify genres\ndef genre_code(column_name):     # genre_code in parameter, column_name is palceholder\n    import ast\n    try: \n        genre_list = ast.literal_eval(column_name)\n        codes = [f'gen{i}' for i in genre_list]\n        return \" \".join(codes)\n    except (ValueError, SysntaxError, TypeError):\n        return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:34:08.486718Z","iopub.execute_input":"2025-11-05T07:34:08.487105Z","iopub.status.idle":"2025-11-05T07:34:08.493081Z","shell.execute_reply.started":"2025-11-05T07:34:08.487079Z","shell.execute_reply":"2025-11-05T07:34:08.491964Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"## applying funciton \ndf4['genres'] = df4['genre_ids'].apply(genre_code)\n# droping existing genre_ids\ndf4 = df4.drop(columns=['genre_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:41:42.656548Z","iopub.execute_input":"2025-11-05T08:41:42.657016Z","iopub.status.idle":"2025-11-05T08:41:46.228614Z","shell.execute_reply.started":"2025-11-05T08:41:42.656990Z","shell.execute_reply":"2025-11-05T08:41:46.227830Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"# view all genres\nall_genres = df4['genres'].dropna().str.split(' ').explode()\nunique_genres = all_genres.nunique()\nprint(unique_genres)\nprint(all_genres.unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T07:57:21.916108Z","iopub.execute_input":"2025-11-05T07:57:21.916866Z","iopub.status.idle":"2025-11-05T07:57:22.900233Z","shell.execute_reply.started":"2025-11-05T07:57:21.916834Z","shell.execute_reply":"2025-11-05T07:57:22.899267Z"}},"outputs":[{"name":"stdout","text":"20\n['gen99' 'gen27' '' 'gen18' 'gen10770' 'gen35' 'gen28' 'gen53' 'gen10749'\n 'gen10402' 'gen16' 'gen10751' 'gen14' 'gen12' 'gen80' 'gen9648' 'gen878'\n 'gen36' 'gen10752' 'gen37']\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"### Working with `release_date`","metadata":{}},{"cell_type":"markdown","source":"```python\ndf4['release_date'] = pd.to_datetime(df4['release_date'], errors='coerce')\n```\n\n* **Purpose:** Converts your `release_date` column into **datetime objects**.\n* `errors='coerce'` → If any row has an invalid date, it becomes `NaT` (Not a Time) instead of crashing.\n* **Output:** The `release_date` column now stores proper date objects, e.g., `'1980-06-30'` becomes `Timestamp('1980-06-30 00:00:00')`.\n\n---\n\n```python\ndf4['year'] = df4['release_date'].dt.year\n```\n\n* **Purpose:** Extracts just the **year** from the datetime column.\n* `.dt.year` is pandas syntax to access the year part of a datetime.\n* **Output:** New column `year`, e.g., `1980`, `1992`, `2005`.\n\n---\n\n```python\ndf4['decade'] = (df4['year'] // 10 * 10).astype('Int64')\n```\n\n* **Purpose:** Groups each year into a **decade**.\n\n  * `// 10` → integer division: `1985 // 10 = 198`\n  * `* 10` → multiply back to get the decade: `198 * 10 = 1980`\n* `.astype('Int64')` → ensures the column is integer type (handles missing values safely).\n* **Output:** New column `decade`, e.g., `1980`, `1990`, `2000`.\n\n---\n\n```python\ndf4['decade_str'] = df4['decade'].astype(str) + 's'\n```\n\n* **Purpose:** Makes a **human-readable string** of the decade.\n* `.astype(str)` → converts numbers to strings\n* `+ 's'` → adds the letter “s” at the end for style, e.g., `1980s`.\n* **Output:** Column `decade_str`, e.g., `'1980s'`, `'1990s'`, `'2000s'`.\n\n---\n\n```python\nprint(df4[['release_date', 'year', 'decade', 'decade_str']].head())\n```\n\n* **Purpose:** Lets you quickly **peek at the first few rows** with all the transformations applied.\n* **Output example:**\n\n```\n  release_date  year  decade decade_str\n0   1980-06-30  1980    1980      1980s\n1   1992-03-15  1992    1990      1990s\n2   2005-08-22  2005    2000      2000s\n3   2010-12-10  2010    2010      2010s\n4   1975-05-07  1975    1970      1970s\n```\n","metadata":{}},{"cell_type":"code","source":"# Make sure the column is datetime\ndf4['release_date'] = pd.to_datetime(df4['release_date'], errors='coerce')\n\n# Extract the year\ndf4['year'] = df4['release_date'].dt.year\n\n# Convert to decade\ndf4['decade'] = (df4['year'] // 10 * 10).astype('Int64')\n\n# make it a string like '1980s'\ndf4['decade_str'] = df4['decade'].astype(str) + 's' # no need, it will remove by `nltk`\n\nprint(df4[['release_date', 'year', 'decade', 'decade_str']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:41:57.444059Z","iopub.execute_input":"2025-11-05T08:41:57.444383Z","iopub.status.idle":"2025-11-05T08:41:57.790809Z","shell.execute_reply.started":"2025-11-05T08:41:57.444358Z","shell.execute_reply":"2025-11-05T08:41:57.789940Z"}},"outputs":[{"name":"stdout","text":"  release_date  year  decade decade_str\n0   1980-06-30  1980    1980      1980s\n1   1980-06-28  1980    1980      1980s\n2   1980-06-28  1980    1980      1980s\n3   1980-06-28  1980    1980      1980s\n4   1980-06-27  1980    1980      1980s\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"### Working on `adults`","metadata":{}},{"cell_type":"code","source":"df4.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:13:06.335957Z","iopub.execute_input":"2025-11-05T08:13:06.336321Z","iopub.status.idle":"2025-11-05T08:13:06.571682Z","shell.execute_reply.started":"2025-11-05T08:13:06.336296Z","shell.execute_reply":"2025-11-05T08:13:06.570826Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"title           0\noverview        0\nrelease_date    0\nadult           0\ntop_cast        0\ndirectors       0\nkeywords        0\nmovie_id        0\ngenres          0\nyear            0\ndecade          0\ndecade_str      0\ndtype: int64"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"# Replace True/False with nsfw/sfw and fill missing with sfw\ndf4['adult'] = df4['adult'].map({True: 'nsfw', False: ''}).fillna('')\n\n# Check\nprint(df4['adult'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:42:05.401452Z","iopub.execute_input":"2025-11-05T08:42:05.401725Z","iopub.status.idle":"2025-11-05T08:42:05.467416Z","shell.execute_reply.started":"2025-11-05T08:42:05.401706Z","shell.execute_reply":"2025-11-05T08:42:05.466633Z"}},"outputs":[{"name":"stdout","text":"adult\n        364512\nnsfw     74715\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"df4.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T08:42:10.608582Z","iopub.execute_input":"2025-11-05T08:42:10.609221Z","iopub.status.idle":"2025-11-05T08:42:10.620862Z","shell.execute_reply.started":"2025-11-05T08:42:10.609193Z","shell.execute_reply":"2025-11-05T08:42:10.619836Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"         title                                           overview  \\\n0  Yorky Billy  YORKY BILLY is set in Ngurgdu (Spring Peak) in...   \n\n  release_date adult         top_cast         directors keywords  movie_id  \\\n0   1980-06-30        ['Yorky Billy']  ['Kim McKenzie']       []   1553504   \n\n  genres  year  decade decade_str  \n0  gen99  1980    1980      1980s  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>overview</th>\n      <th>release_date</th>\n      <th>adult</th>\n      <th>top_cast</th>\n      <th>directors</th>\n      <th>keywords</th>\n      <th>movie_id</th>\n      <th>genres</th>\n      <th>year</th>\n      <th>decade</th>\n      <th>decade_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yorky Billy</td>\n      <td>YORKY BILLY is set in Ngurgdu (Spring Peak) in...</td>\n      <td>1980-06-30</td>\n      <td></td>\n      <td>['Yorky Billy']</td>\n      <td>['Kim McKenzie']</td>\n      <td>[]</td>\n      <td>1553504</td>\n      <td>gen99</td>\n      <td>1980</td>\n      <td>1980</td>\n      <td>1980s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":91},{"cell_type":"markdown","source":"we can see top_cast, directors, keywords are in list with multiple value. so we can make a funtin to convert them into one string list. because we need only the tags. so we will remove all spaces in each values. then make them lowercase and saparate them with space by replacing the comma.\n```\ndf4['top_cast'].head(10)\ndf4['directors'].head(10)\ndf4['keywords'].head(10)\n```","metadata":{"execution":{"iopub.status.busy":"2025-11-05T08:27:50.910526Z","iopub.execute_input":"2025-11-05T08:27:50.910849Z","iopub.status.idle":"2025-11-05T08:27:50.918624Z","shell.execute_reply.started":"2025-11-05T08:27:50.910824Z","shell.execute_reply":"2025-11-05T08:27:50.917396Z"}}},{"cell_type":"code","source":"def list_tags(obj):\n    List = []\n    for i in ast.literal_eval(obj):\n        List.append(i)\n    tags = ', '.join(List)\n    tags = tags.lower().replace(\" \", \"\").replace(\",\", \" \").replace(\"-\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n    return tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:24:37.803101Z","iopub.execute_input":"2025-11-05T09:24:37.803428Z","iopub.status.idle":"2025-11-05T09:24:37.809454Z","shell.execute_reply.started":"2025-11-05T09:24:37.803403Z","shell.execute_reply":"2025-11-05T09:24:37.808467Z"}},"outputs":[],"execution_count":146},{"cell_type":"code","source":"df4.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:27:07.939404Z","iopub.execute_input":"2025-11-05T09:27:07.940172Z","iopub.status.idle":"2025-11-05T09:27:07.954562Z","shell.execute_reply.started":"2025-11-05T09:27:07.940137Z","shell.execute_reply":"2025-11-05T09:27:07.953731Z"}},"outputs":[{"execution_count":149,"output_type":"execute_result","data":{"text/plain":"         title                                           overview  \\\n0  Yorky Billy  YORKY BILLY is set in Ngurgdu (Spring Peak) in...   \n\n  release_date adult         top_cast         directors keywords  movie_id  \\\n0   1980-06-30        ['Yorky Billy']  ['Kim McKenzie']       []   1553504   \n\n  genres  year  decade decade_str  \n0  gen99  1980    1980      1980s  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>overview</th>\n      <th>release_date</th>\n      <th>adult</th>\n      <th>top_cast</th>\n      <th>directors</th>\n      <th>keywords</th>\n      <th>movie_id</th>\n      <th>genres</th>\n      <th>year</th>\n      <th>decade</th>\n      <th>decade_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yorky Billy</td>\n      <td>YORKY BILLY is set in Ngurgdu (Spring Peak) in...</td>\n      <td>1980-06-30</td>\n      <td></td>\n      <td>['Yorky Billy']</td>\n      <td>['Kim McKenzie']</td>\n      <td>[]</td>\n      <td>1553504</td>\n      <td>gen99</td>\n      <td>1980</td>\n      <td>1980</td>\n      <td>1980s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":149},{"cell_type":"code","source":"df5 = df4.copy()\ndf5['keywords'] = df5['keywords'].apply(list_tags)\ndf5['top_cast'] = df5['top_cast'].apply(list_tags)\ndf5['directors'] = df5['directors'].apply(list_tags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:35:38.505645Z","iopub.execute_input":"2025-11-05T09:35:38.506046Z","iopub.status.idle":"2025-11-05T09:35:51.629565Z","shell.execute_reply.started":"2025-11-05T09:35:38.506019Z","shell.execute_reply":"2025-11-05T09:35:51.628743Z"}},"outputs":[],"execution_count":160},{"cell_type":"code","source":"df5.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:28:54.224285Z","iopub.execute_input":"2025-11-05T09:28:54.224952Z","iopub.status.idle":"2025-11-05T09:28:54.237581Z","shell.execute_reply.started":"2025-11-05T09:28:54.224913Z","shell.execute_reply":"2025-11-05T09:28:54.236784Z"}},"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"         title                                           overview  \\\n0  Yorky Billy  YORKY BILLY is set in Ngurgdu (Spring Peak) in...   \n\n  release_date adult    top_cast    directors keywords  movie_id genres  year  \\\n0   1980-06-30        yorkybilly  kimmckenzie            1553504  gen99  1980   \n\n   decade decade_str  \n0    1980      1980s  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>overview</th>\n      <th>release_date</th>\n      <th>adult</th>\n      <th>top_cast</th>\n      <th>directors</th>\n      <th>keywords</th>\n      <th>movie_id</th>\n      <th>genres</th>\n      <th>year</th>\n      <th>decade</th>\n      <th>decade_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yorky Billy</td>\n      <td>YORKY BILLY is set in Ngurgdu (Spring Peak) in...</td>\n      <td>1980-06-30</td>\n      <td></td>\n      <td>yorkybilly</td>\n      <td>kimmckenzie</td>\n      <td></td>\n      <td>1553504</td>\n      <td>gen99</td>\n      <td>1980</td>\n      <td>1980</td>\n      <td>1980s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":152},{"cell_type":"markdown","source":"now as we converted imported columns into single string sentence. now we can perform concatination by converting them into list. before we start, we will copy the title to include them into tags","metadata":{}},{"cell_type":"code","source":"df5['title_x'] = df5['title']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:35:51.630978Z","iopub.execute_input":"2025-11-05T09:35:51.631251Z","iopub.status.idle":"2025-11-05T09:35:51.640832Z","shell.execute_reply.started":"2025-11-05T09:35:51.631220Z","shell.execute_reply":"2025-11-05T09:35:51.639737Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"# collecting neccessery columns\ndf6 = df5[['movie_id', 'title','title_x', 'overview', 'adult', 'top_cast', 'directors', 'keywords', 'genres', 'decade_str']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:35:51.642135Z","iopub.execute_input":"2025-11-05T09:35:51.642400Z","iopub.status.idle":"2025-11-05T09:35:51.707021Z","shell.execute_reply.started":"2025-11-05T09:35:51.642380Z","shell.execute_reply":"2025-11-05T09:35:51.706172Z"}},"outputs":[],"execution_count":162},{"cell_type":"code","source":"columns = ['title_x', 'overview', 'adult', 'top_cast', 'directors', 'keywords', 'genres', 'decade_str']\nfor i in columns:\n    df6[i] = df6[i].apply(lambda x:x.lower().split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:36:54.231612Z","iopub.execute_input":"2025-11-05T09:36:54.232349Z","iopub.status.idle":"2025-11-05T09:37:07.810713Z","shell.execute_reply.started":"2025-11-05T09:36:54.232322Z","shell.execute_reply":"2025-11-05T09:37:07.809898Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/103411960.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df6[i] = df6[i].apply(lambda x:x.lower().split())\n","output_type":"stream"}],"execution_count":164},{"cell_type":"code","source":"df6.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:37:14.836830Z","iopub.execute_input":"2025-11-05T09:37:14.837209Z","iopub.status.idle":"2025-11-05T09:37:14.854153Z","shell.execute_reply.started":"2025-11-05T09:37:14.837183Z","shell.execute_reply":"2025-11-05T09:37:14.853209Z"}},"outputs":[{"execution_count":165,"output_type":"execute_result","data":{"text/plain":"   movie_id        title         title_x  \\\n0   1553504  Yorky Billy  [yorky, billy]   \n\n                                            overview adult      top_cast  \\\n0  [yorky, billy, is, set, in, ngurgdu, (spring, ...    []  [yorkybilly]   \n\n       directors keywords   genres decade_str  \n0  [kimmckenzie]       []  [gen99]    [1980s]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>title_x</th>\n      <th>overview</th>\n      <th>adult</th>\n      <th>top_cast</th>\n      <th>directors</th>\n      <th>keywords</th>\n      <th>genres</th>\n      <th>decade_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1553504</td>\n      <td>Yorky Billy</td>\n      <td>[yorky, billy]</td>\n      <td>[yorky, billy, is, set, in, ngurgdu, (spring, ...</td>\n      <td>[]</td>\n      <td>[yorkybilly]</td>\n      <td>[kimmckenzie]</td>\n      <td>[]</td>\n      <td>[gen99]</td>\n      <td>[1980s]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":165},{"cell_type":"code","source":"df6.iloc[7].keywords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:39:18.270002Z","iopub.execute_input":"2025-11-05T09:39:18.270343Z","iopub.status.idle":"2025-11-05T09:39:18.276698Z","shell.execute_reply.started":"2025-11-05T09:39:18.270317Z","shell.execute_reply":"2025-11-05T09:39:18.275833Z"}},"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"['chicago',\n 'illinois',\n 'posttraumaticstressdisorderptsd',\n 'airplane',\n 'cataclysm',\n 'guitar',\n 'alcohol',\n 'stewardess',\n 'taxidriver',\n 'passenger',\n 'fearofflying',\n 'pilot',\n 'medicine',\n 'aircontroller',\n 'landing',\n 'saxophone',\n 'autopilot',\n 'parody',\n 'spoof',\n 'foodpoisoning',\n 'losangeles',\n 'california',\n 'alcoholabuse',\n 'aftercreditsstinger',\n 'inflatableliferaft',\n 'anarchiccomedy']"},"metadata":{}}],"execution_count":169},{"cell_type":"markdown","source":"as we used .spit(), it automatically seperates each word with comma. but no problem. we can now contat each clumns now","metadata":{}},{"cell_type":"code","source":"df7 = df6.copy()\ndf7['tags'] = df7['title_x']+df7['overview']+df7['adult']+df7['top_cast']+df7['directors']+df7['keywords']+df7['genres']+df7['decade_str']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:43:45.359985Z","iopub.execute_input":"2025-11-05T09:43:45.360488Z","iopub.status.idle":"2025-11-05T09:43:59.266932Z","shell.execute_reply.started":"2025-11-05T09:43:45.360450Z","shell.execute_reply":"2025-11-05T09:43:59.265805Z"}},"outputs":[],"execution_count":170},{"cell_type":"markdown","source":"### trainning model","metadata":{}},{"cell_type":"code","source":"# finally lets create our movies dataframe\nmovies = df7[['movie_id', 'title', 'tags']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:45:07.141130Z","iopub.execute_input":"2025-11-05T09:45:07.141539Z","iopub.status.idle":"2025-11-05T09:45:07.164040Z","shell.execute_reply.started":"2025-11-05T09:45:07.141513Z","shell.execute_reply":"2025-11-05T09:45:07.162966Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"movies.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:45:57.633939Z","iopub.execute_input":"2025-11-05T09:45:57.634228Z","iopub.status.idle":"2025-11-05T09:45:57.645008Z","shell.execute_reply.started":"2025-11-05T09:45:57.634207Z","shell.execute_reply":"2025-11-05T09:45:57.644146Z"}},"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"   movie_id                       title  \\\n0   1553504                 Yorky Billy   \n1   1499587              Dark Vengeance   \n2    495099  The Master and Ms. Johnson   \n\n                                                tags  \n0  [yorky, billy, yorky, billy, is, set, in, ngur...  \n1  [dark, vengeance, dark, vengeance, is, a, 1980...  \n2  [the, master, and, ms., johnson, sexually, mal...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1553504</td>\n      <td>Yorky Billy</td>\n      <td>[yorky, billy, yorky, billy, is, set, in, ngur...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1499587</td>\n      <td>Dark Vengeance</td>\n      <td>[dark, vengeance, dark, vengeance, is, a, 1980...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>495099</td>\n      <td>The Master and Ms. Johnson</td>\n      <td>[the, master, and, ms., johnson, sexually, mal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":173},{"cell_type":"code","source":"movies['tags'] = movies['tags'].apply(lambda x: ' '.join(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:49:27.352737Z","iopub.execute_input":"2025-11-05T09:49:27.353140Z","iopub.status.idle":"2025-11-05T09:49:28.340420Z","shell.execute_reply.started":"2025-11-05T09:49:27.353112Z","shell.execute_reply":"2025-11-05T09:49:28.339283Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/2303228016.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  movies['tags'] = movies['tags'].apply(lambda x: ' '.join(x))\n","output_type":"stream"}],"execution_count":177},{"cell_type":"code","source":"movies.iloc[7].tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:49:31.255677Z","iopub.execute_input":"2025-11-05T09:49:31.256016Z","iopub.status.idle":"2025-11-05T09:49:31.262827Z","shell.execute_reply.started":"2025-11-05T09:49:31.255993Z","shell.execute_reply":"2025-11-05T09:49:31.262036Z"}},"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"'airplane! an ex-fighter pilot forced to take over the controls of an airliner when the flight crew succumbs to food poisoning. roberthays juliehagerty leslienielsen kareemabduljabbar lloydbridges jimabrahams jerryzucker davidzucker chicago illinois posttraumaticstressdisorderptsd airplane cataclysm guitar alcohol stewardess taxidriver passenger fearofflying pilot medicine aircontroller landing saxophone autopilot parody spoof foodpoisoning losangeles california alcoholabuse aftercreditsstinger inflatableliferaft anarchiccomedy gen35 1980s'"},"metadata":{}}],"execution_count":178},{"cell_type":"markdown","source":"here we can see some extra symbols like `.`, `!`, `'` etc. we can remove it but not now. we will use some libraires from natural language procees `nltk` and stop words in vectorizing. that will handle that.\n\nalso Handling simmiler words like `loved`, `loving` to `love`, `love`.\nit will require nltk library from natural language proccessing. if you are running this notbook on your local computer, you may install it by `!pip install nltk`","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:52:38.088342Z","iopub.execute_input":"2025-11-05T09:52:38.088670Z","iopub.status.idle":"2025-11-05T09:52:38.093818Z","shell.execute_reply.started":"2025-11-05T09:52:38.088649Z","shell.execute_reply":"2025-11-05T09:52:38.092724Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"# we will stem each words in tags.\ndef stem(text):\n    a = []\n    for i in text.split(): # first it will split the paragraph into comma separated format\n        a.append(ps.stem(i)) # then it will stem each words\n    return \" \".join(a) # then it will append each stemed word again into paragraph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:54:34.371257Z","iopub.execute_input":"2025-11-05T09:54:34.371648Z","iopub.status.idle":"2025-11-05T09:54:34.377262Z","shell.execute_reply.started":"2025-11-05T09:54:34.371621Z","shell.execute_reply":"2025-11-05T09:54:34.376356Z"}},"outputs":[],"execution_count":181},{"cell_type":"code","source":"movies['tags'] = movies['tags'].apply(stem)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T09:55:08.273478Z","iopub.execute_input":"2025-11-05T09:55:08.273901Z","iopub.status.idle":"2025-11-05T10:00:39.191330Z","shell.execute_reply.started":"2025-11-05T09:55:08.273854Z","shell.execute_reply":"2025-11-05T10:00:39.190203Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/3456099318.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  movies['tags'] = movies['tags'].apply(stem)\n","output_type":"stream"}],"execution_count":182},{"cell_type":"code","source":"movies.iloc[7].tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:00:39.192868Z","iopub.execute_input":"2025-11-05T10:00:39.193196Z","iopub.status.idle":"2025-11-05T10:00:39.200270Z","shell.execute_reply.started":"2025-11-05T10:00:39.193175Z","shell.execute_reply":"2025-11-05T10:00:39.199615Z"}},"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"'airplane! an ex-fight pilot forc to take over the control of an airlin when the flight crew succumb to food poisoning. roberthay juliehagerti leslienielsen kareemabduljabbar lloydbridg jimabraham jerryzuck davidzuck chicago illinoi posttraumaticstressdisorderptsd airplan cataclysm guitar alcohol stewardess taxidriv passeng fearoffli pilot medicin aircontrol land saxophon autopilot parodi spoof foodpoison losangel california alcoholabus aftercreditssting inflatableliferaft anarchiccomedi gen35 1980'"},"metadata":{}}],"execution_count":183},{"cell_type":"markdown","source":"in our current dataset, it has a large number or rows. that's why stemming will take a lots of time. we will store it as csv. sothat when we will work on it, we can easily load it.","metadata":{}},{"cell_type":"code","source":"movies.to_csv('movies_stemmed.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:40:19.736224Z","iopub.execute_input":"2025-11-05T10:40:19.737835Z","iopub.status.idle":"2025-11-05T10:40:19.765253Z","shell.execute_reply.started":"2025-11-05T10:40:19.737794Z","shell.execute_reply":"2025-11-05T10:40:19.763761Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_160/2024873980.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'movies_stemmed.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"],"ename":"NameError","evalue":"name 'movies' is not defined","output_type":"error"}],"execution_count":11},{"cell_type":"markdown","source":"# lets vectorize the moves datafrmae","metadata":{}},{"cell_type":"code","source":"movies_stem = pd.read_csv('/kaggle/input/stemmed-movies/movies_stemmed.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:20:38.071175Z","iopub.execute_input":"2025-11-05T12:20:38.071680Z","iopub.status.idle":"2025-11-05T12:20:43.741904Z","shell.execute_reply.started":"2025-11-05T12:20:38.071650Z","shell.execute_reply":"2025-11-05T12:20:43.740768Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"before we make vector, we have to reduce the dimension of the dataset. so we will manually remove some unwanted words.","metadata":{}},{"cell_type":"markdown","source":"## filtering stop words using library","metadata":{}},{"cell_type":"code","source":"# download once\nnltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    words = text.split()  # assuming text is already stemmed and lowercase\n    filtered = [w for w in words if w not in stop_words]\n    return \" \".join(filtered)\n\nmovies_stem['tags'] = movies_stem['tags'].apply(remove_stopwords)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:20:43.743252Z","iopub.execute_input":"2025-11-05T12:20:43.743773Z","iopub.status.idle":"2025-11-05T12:20:48.206206Z","shell.execute_reply.started":"2025-11-05T12:20:43.743741Z","shell.execute_reply":"2025-11-05T12:20:48.205270Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Showing top words\n\n#### do the step furtun to make the best custom stopwords","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\n# split all tags into words\nall_words = []\nfor tags in movies_stem['tags']:\n    all_words.extend(tags.split())\n\n# count frequency\nword_counts = Counter(all_words)\n# show top 50 words\ntop = word_counts.most_common(10)   # use 100 for more view\nfor word, count in top:\n    print(word, \" ->\",count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:10:07.756066Z","iopub.execute_input":"2025-11-05T12:10:07.756337Z","iopub.status.idle":"2025-11-05T12:10:15.255938Z","shell.execute_reply.started":"2025-11-05T12:10:07.756317Z","shell.execute_reply":"2025-11-05T12:10:15.254763Z"}},"outputs":[{"name":"stdout","text":"gen99  -> 83157\nnsfw  -> 74732\ngen18  -> 72536\ngen35  -> 52316\nlive  -> 45426\nyoung  -> 40960\nstori  -> 40238\nlove  -> 39685\nlife  -> 38952\n1990  -> 38101\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## using custom stop words","metadata":{}},{"cell_type":"code","source":"custom_stopwords = ['hi','thi', 'ha', 'film', 'new','-','wa','take', 'two', 'find','get','year','want','2','&','use','it','see','2000','2010','2020',\"it'\",'go','watch','one','make','must','give']\n\ndef custom_filter(tags):\n    words = tags.split()\n    filtered = [w for w in words if w not in custom_stopwords]\n    return \" \".join(filtered)\n\nmovies_stem['tags'] = movies_stem['tags'].apply(custom_filter)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:20:51.892054Z","iopub.execute_input":"2025-11-05T12:20:51.892378Z","iopub.status.idle":"2025-11-05T12:21:00.233904Z","shell.execute_reply.started":"2025-11-05T12:20:51.892353Z","shell.execute_reply":"2025-11-05T12:21:00.232918Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# check average tags per movies\nmovies_stem['tags'].apply(lambda x: len(x.split())).describe()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T10:31:12.792585Z","iopub.execute_input":"2025-11-05T10:31:12.793986Z","iopub.status.idle":"2025-11-05T10:31:14.534728Z","shell.execute_reply.started":"2025-11-05T10:31:12.793948Z","shell.execute_reply":"2025-11-05T10:31:14.533813Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"count    439227.000000\nmean         56.112860\nstd          36.066442\nmin           2.000000\n25%          30.000000\n50%          47.000000\n75%          74.000000\nmax         237.000000\nName: tags, dtype: float64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# check average tags per movies\nmovies_stem['tags'].apply(lambda x: len(x.split())).describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T11:31:20.507371Z","iopub.execute_input":"2025-11-05T11:31:20.507709Z","iopub.status.idle":"2025-11-05T11:31:21.713666Z","shell.execute_reply.started":"2025-11-05T11:31:20.507689Z","shell.execute_reply":"2025-11-05T11:31:21.712786Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"count    439227.000000\nmean         35.026651\nstd          21.295661\nmin           0.000000\n25%          20.000000\n50%          30.000000\n75%          46.000000\nmax         188.000000\nName: tags, dtype: float64"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"vector = movies_stem.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:21:02.888379Z","iopub.execute_input":"2025-11-05T12:21:02.888773Z","iopub.status.idle":"2025-11-05T12:21:02.963115Z","shell.execute_reply.started":"2025-11-05T12:21:02.888677Z","shell.execute_reply":"2025-11-05T12:21:02.961879Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(max_features=100000,  # 100000 failed;\n                        min_df=5,            # ignore words in <5 movies; to-do 5\n                        max_df=0.7         # ignore words in >70% movies\n                        #stop_words='english'\n                       ) # used before\ntfidf_matrix = tfidf.fit_transform(vector['tags'])  # returns a sparse matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:28:47.642413Z","iopub.execute_input":"2025-11-05T12:28:47.642714Z","iopub.status.idle":"2025-11-05T12:29:09.195725Z","shell.execute_reply.started":"2025-11-05T12:28:47.642691Z","shell.execute_reply":"2025-11-05T12:29:09.194705Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tfidf_sums = np.array(tfidf_matrix.sum(axis=0)).flatten()\nwords = tfidf.get_feature_names_out()\n\nword_tfidf = pd.DataFrame({'word': words, 'tfidf_sum': tfidf_sums})\nword_tfidf = word_tfidf.sort_values(by='tfidf_sum', ascending=False)\nprint(word_tfidf.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:11:50.010704Z","iopub.execute_input":"2025-11-05T12:11:50.011092Z","iopub.status.idle":"2025-11-05T12:11:50.051792Z","shell.execute_reply.started":"2025-11-05T12:11:50.011065Z","shell.execute_reply":"2025-11-05T12:11:50.050654Z"}},"outputs":[{"name":"stdout","text":"       word    tfidf_sum\n1932  gen18  8194.509184\n1942  gen99  8029.447525\n3131   nsfw  7577.729375\n1935  gen35  6427.680930\n2643   life  5928.241754\n2717   love  5347.971172\n54     1990  5341.576831\n2773    man  5229.773033\n4986  young  5117.987131\n2674   live  5108.471278\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\n\n# use a fast approximate metric\nnn = NearestNeighbors(metric='cosine', algorithm='brute')  \nnn.fit(tfidf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:29:09.196926Z","iopub.execute_input":"2025-11-05T12:29:09.197205Z","iopub.status.idle":"2025-11-05T12:29:09.275155Z","shell.execute_reply.started":"2025-11-05T12:29:09.197178Z","shell.execute_reply":"2025-11-05T12:29:09.274105Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"NearestNeighbors(algorithm='brute', metric='cosine')","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def recommend(movie):\n    movie_index = movies_stem[movies_stem['title'] == movie].index[0]\n    distances = similarity[movie_index]\n    movies_list = sorted(list(enumerate(distances)),reverse=True, key = lambda x:x[1])[1:21] # we can remove [0] as we did it n `distance`\n\n    for i in movies_list:\n        print(movies_stem.iloc[i[0]].title)\nrecommend(\"Pirates of the Caribbean: At World's End\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:21:47.012225Z","iopub.execute_input":"2025-11-05T12:21:47.012628Z","iopub.status.idle":"2025-11-05T12:21:47.020005Z","shell.execute_reply.started":"2025-11-05T12:21:47.012595Z","shell.execute_reply":"2025-11-05T12:21:47.018637Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def recommend(movie):\n    # find the index of the movie\n    movie_index = movies_stem[movies_stem['title'] == movie].index[0]\n\n    # query for nearest neighbors\n    distances, indices = nn.kneighbors(tfidf_matrix[movie_index], n_neighbors=11)\n\n    # skip the first one (it’s the movie itself)\n    for i in range(1, len(indices[0])):\n        print(movies_stem.iloc[indices[0][i]].title)\nprint(\"\\n==============================\\n\\n✅ All Tranning Compleate....!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:26:20.131975Z","iopub.execute_input":"2025-11-05T12:26:20.132696Z","iopub.status.idle":"2025-11-05T12:26:20.139373Z","shell.execute_reply.started":"2025-11-05T12:26:20.132663Z","shell.execute_reply":"2025-11-05T12:26:20.138350Z"}},"outputs":[{"name":"stdout","text":"\n==============================\n\n✅ All Tranning Compleate....!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"recommend(\"Iron Man\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T12:30:33.555245Z","iopub.execute_input":"2025-11-05T12:30:33.555659Z","iopub.status.idle":"2025-11-05T12:30:34.179448Z","shell.execute_reply.started":"2025-11-05T12:30:33.555634Z","shell.execute_reply":"2025-11-05T12:30:34.178304Z"}},"outputs":[{"name":"stdout","text":"Iron Man 2\nIron Man 3\nSpider-Man: Homecoming\nI Am Iron Man\nThe Invincible Iron Man\nIron Man XXX: An Extreme Comixxx Parody\nSpider-Man: Far From Home\nCaptain America: Civil War\nThe Avengers\nGuardians of the Galaxy Vol. 2\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}